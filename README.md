# Toxic-Comment-Classifier
 This project focuses on classifying various types of toxic comments, including categories such as toxic, severely toxic, obscene, threat, insult, and identity hate. The classification model is built using Python, leveraging TensorFlow and Keras for deep learning. The dataset consists of user comments that have been labeled for these categories.
Project Overview
The goal of this project is to develop a model that can accurately detect and categorize different types of toxic comments. The project involves data preprocessing, model training, and evaluation. The trained model can be used to identify and filter toxic comments in various online platforms, enhancing the quality of user interactions.

Key Features
Data Preprocessing: Cleaning and preparing the dataset for training, including handling missing values, tokenization, and vectorization.
Model Training: Using LSTM networks for handling sequential data, with multiple epochs and different configurations to optimize performance.
Evaluation and Analysis: Visualizing training metrics, such as loss and accuracy, to understand model performance.
